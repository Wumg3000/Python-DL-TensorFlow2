{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support CUDA ?:  True\n",
      "tensor([10.], device='cuda:0')\n",
      "tensor([[ 1.3160,  2.2686, -0.5073],\n",
      "        [-0.0096, -0.2778, -0.2917]], device='cuda:0')\n",
      "tensor([[11.3160, 12.2686,  9.4927],\n",
      "        [ 9.9904,  9.7222,  9.7083]], device='cuda:0')\n",
      "Support cudnn ?:  True\n"
     ]
    }
   ],
   "source": [
    "#运行文件test_gpy.py,查看GPU的配置信息\n",
    "!python test_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 NumPy与Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.1  torch概述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 6])\n",
      "tensor([1, 2])\n",
      "tensor([4, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "x=torch.tensor([1,2])\n",
    "y=torch.tensor([3,4])\n",
    "z=x.add(y)\n",
    "print(z)\n",
    "print(x)\n",
    "x.add_(y)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.2 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1457e-35,  6.3058e-43,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "#根据list数据生成tensor\n",
    "torch.Tensor([1,2,3,4,5,6])\n",
    "#根据指定形状生成tensor\n",
    "torch.Tensor(2,3)\n",
    "#根据给定的tensor的形状\n",
    "t=torch.Tensor([[1,2,3],[4,5,6]])\n",
    "#查看tensor的形状\n",
    "t.size()\n",
    "#shape与size()等价方式\n",
    "t.shape\n",
    "#根据已有形状创建tensor\n",
    "torch.Tensor(t.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1的值tensor([0.]),t1的数据类型torch.FloatTensor\n",
      "t2的值1,t2的数据类型torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "#torch.tensor与torch.Tentor的区别\n",
    "import torch\n",
    "t1=torch.Tensor(1)\n",
    "t2=torch.tensor(1)\n",
    "print(\"t1的值{},t1的数据类型{}\".format(t1,t1.type()))\n",
    "print(\"t2的值{},t2的数据类型{}\".format(t2,t2.type()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据一定规则，自动生成tensor的一些例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#生成一个单位矩阵\n",
    "torch.eye(2,2)\n",
    "#自动生成全是0的矩阵\n",
    "torch.zeros(2,3)\n",
    "#根据规则生成数据\n",
    "torch.linspace(1,10,4)\n",
    "#生成满足均匀分布随机数\n",
    "torch.rand(2,3)\n",
    "#生成满足标准分布随机数\n",
    "torch.randn(2,3)\n",
    "#返回所给数据形状相同，值全为0的张量\n",
    "torch.zeros_like(torch.rand(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.3 修改tensor的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#生成一个形状为2x3的矩阵\n",
    "x = torch.randn(2, 3)\n",
    "#查看矩阵的形状\n",
    "x.size()   #结果为torch.Size([2, 3])\n",
    "\n",
    "#查看x的维度\n",
    "x.dim()    #结果为2\n",
    "#把x变为3x2的矩阵\n",
    "x.view(3,2)\n",
    "#把x展平为1维向量\n",
    "y=x.view(-1)  \n",
    "y.shape\n",
    "#添加一个维度\n",
    "z=torch.unsqueeze(y,0)\n",
    "#查看z的形状\n",
    "z.size()   #结果为torch.Size([1, 6])\n",
    "#计算Z的元素个数\n",
    "z.numel()   #结果为6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.4 索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3607, -0.2859,  0.0000],\n",
       "        [ 0.0000, -1.3833,  0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "#设置一个随机种子\n",
    "torch.manual_seed(100) \n",
    "#生成一个形状为2x3的矩阵\n",
    "x = torch.randn(2, 3)\n",
    "#根据索引获取第1行，所有数据\n",
    "x[0,:]\n",
    "#获取最后一列数据\n",
    "x[:,-1]\n",
    "#生成是否大于0的Byter张量\n",
    "mask=x>0\n",
    "#获取大于0的值\n",
    "torch.masked_select(x,mask)\n",
    "#获取非0下标,即行，列索引\n",
    "torch.nonzero(mask)\n",
    "#获取指定索引对应的值,输出根据以下规则得到\n",
    "#out[i][j] = input[index[i][j]][j]  # if dim == 0\n",
    "#out[i][j] = input[i][index[i][j]]  # if dim == 1\n",
    "index=torch.LongTensor([[0,1,1]])\n",
    "torch.gather(x,0,index)\n",
    "index=torch.LongTensor([[0,1,1],[1,1,1]])\n",
    "a=torch.gather(x,1,index)\n",
    "#把a的值返回到一个2x3的0矩阵中\n",
    "z=torch.zeros(2,3)\n",
    "z.scatter_(1,index,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.5 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [10, 11, 12],\n",
      "        [20, 21, 22],\n",
      "        [30, 31, 32]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "A = np.arange(0, 40,10).reshape(4, 1)\n",
    "B = np.arange(0, 3)\n",
    "#把ndarray转换为Tensor\n",
    "A1=torch.from_numpy(A)  #形状为4x1\n",
    "B1=torch.from_numpy(B)  #形状为3\n",
    "#Tensor自动实现广播\n",
    "C=A1+B1\n",
    "#我们可以根据广播机制，手工进行配置\n",
    "#根据规则1，B1需要向A1看齐，把B变为（1,3）\n",
    "B2=B1.unsqueeze(0)  #B2的形状为1x3\n",
    "#使用expand函数重复数组，分别的4x3的矩阵\n",
    "A2=A1.expand(4,3)\n",
    "B3=B2.expand(4,3)\n",
    "#然后进行相加,C1与C结果一致\n",
    "C1=A2+B3\n",
    "print(C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.6 遂元操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6828, 1.1340, 3.7482]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.randn(1, 3)\n",
    "t1 = torch.randn(3, 1)\n",
    "t2 = torch.randn(1, 3)\n",
    "#t+0.1*(t1/t2)\n",
    "torch.addcdiv(t, t1, t2,value=0.1)\n",
    "#计算sigmoid\n",
    "torch.sigmoid(t)\n",
    "#将t限制在[0,1]之间\n",
    "torch.clamp(t,0,1)\n",
    "#t+2进行就地运算\n",
    "t.add_(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.7 归并操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#生成一个含6个数的向量\n",
    "a=torch.linspace(0,10,6)\n",
    "#使用view方法，把a变为2x3矩阵\n",
    "a=a.view((2,3))\n",
    "#沿y轴方向累加，即dim=0\n",
    "b=a.sum(dim=0)   #b的形状为[3]\n",
    "#沿y轴方向累加，即dim=0,并保留含1的维度\n",
    "b=a.sum(dim=0,keepdim=True) #b的形状为[1,3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.8比较操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 6.,  8., 10.]]),\n",
       "indices=tensor([[1, 1, 1]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.linspace(0,10,6).view(2,3)\n",
    "#求所有元素的最大值\n",
    "torch.max(x)   #结果为10\n",
    "#求y轴方向的最大值\n",
    "torch.max(x,dim=0)  #结果为[6,8,10]\n",
    "#求最大的2个元素\n",
    "torch.topk(x,1,dim=0)  #结果为[6,8,10],对应索引为tensor([[1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.9 矩阵操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[28, 77, 30, 27],\n",
       "         [24, 73, 25, 21]],\n",
       "\n",
       "        [[15, 68, 57,  6],\n",
       "         [25, 39, 43, 10]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.tensor([2, 3])\n",
    "b=torch.tensor([3, 4])\n",
    "\n",
    "torch.dot(a,b)  #运行结果为18\n",
    "x=torch.randint(10,(2,3))\n",
    "y=torch.randint(6,(3,4))\n",
    "torch.mm(x,y)\n",
    "x=torch.randint(10,(2,2,3))\n",
    "y=torch.randint(6,(2,3,4))\n",
    "torch.bmm(x,y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
